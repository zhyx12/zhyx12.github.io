<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">






  <link rel="canonical" href="http://yoursite.com/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Hexo</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/05/distribution-adaptation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/05/distribution-adaptation/" itemprop="url">
                  Distribution Adaptation
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-09-05 17:14:45 / Modified: 17:14:56" itemprop="dateCreated datePublished" datetime="2018-09-05T17:14:45+08:00">2018-09-05</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="方法">方法</h1>
<p>Distributing Adaptation是数据分布自适应，这里主要介绍DA中的数据分布自适用的浅层方法。</p>
<p>分为边缘分布自适应，条件分布自适应和联合分布自适应。其中边缘分布自适应是最早也是最基础的方法。</p>
<p>TCA是经典的边缘分布自适应方法，使用了MMD准则作为领域（分布）之间距离的度量方法。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/05/DA-in-semantic-segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/05/DA-in-semantic-segmentation/" itemprop="url">
                  DA in Semantic Segmentation
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-09-05 17:14:11 / Modified: 17:15:56" itemprop="dateCreated datePublished" datetime="2018-09-05T17:14:11+08:00">2018-09-05</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据集">数据集</h1>
<p>Cityscapes</p>
<p>SYNTHIA</p>
<p>GTA5</p>
<p>BDDS</p>
<h1 id="论文">论文</h1>
<p>全卷积网络在密集预测中被认为是有效的，但是遇到领域偏移的时候效果会下降。一些工作利用弱标签来提升语义分割的效果。<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>中使用带注意力机制的编码解码结构来迁移弱的类别标签，<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>中迁移物体的位置信息。</p>
<p>更多的工作关注语义分割中的深度无监督域适应。</p>
<h2 id="section"></h2>
<p><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> 首先引入了这一概念，在FCN上进行对抗式的训练以实现整个领域的对齐。迁移空间布局是利用类别相关的constrained multiple instance loss。<a href="https://github.com/Wanger-SJTU/FCN-in-the-wild" target="_blank" rel="external">代码，pytorch</a> 数据集：Cityscapes， SYNTHIA，GTA5，BDDS</p>
<h2 id="section-1"></h2>
<p><a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> ICCV2017 使用虚拟图像来增强现实图像的语义分割效果，使用了图像级别的全局标签分布损失，和超像素级别的局部标签分布损失来正则化模型的微调过程。<a href="https://github.com/YangZhang4065/AdaptationSeg" target="_blank" rel="external">代码，keras</a> 数据集：Cityscapes， SYNTHIA，GTA5</p>
<h2 id="section-2"></h2>
<p><a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>中跨城市语义分割的框架，为目标域的像素赋予伪标签，然后通过领域对抗学习实现全局和类别的对齐。<a href="">代码</a></p>
<h2 id="section-3"></h2>
<p><a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> CVPR2018 使用了目标引导的蒸馏模型来迁移真实图像的风格，同时使用了空间感知适应模块来利用内在的空间结构来减小领域偏移。不同于在特征空间上直接进行简单的对抗损失。<a href="http://www.vision.ee.ethz.ch/~yuhchen/" target="_blank" rel="external">作者主页</a> 数据集：GTA5→Cityscapes</p>
<h2 id="section-4"></h2>
<p><a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> CVPR2018 使用了GAN将特征映射到图像空间，并在图像空间使用判别器。<a href="https://github.com/swamiviv/LSD-seg" target="_blank" rel="external">代码，pytorch</a></p>
<p>数据集：SYNTHIA→CITYSCAPES，GTAV→CITYSCAPES</p>
<h2 id="section-5"></h2>
<p><a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> CVPR2018，<a href="https://github.com/wasidennis/AdaptSegNet" target="_blank" rel="external">代码</a></p>
<p>数据集： GTA5→Cityscapes，SYNTHIA→Cityscapes</p>
<h2 id="section-6"></h2>
<p><a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> CVPR2018</p>
<p>数据集：GTA5→Cityscapes，SYNTHIA→Cityscapes</p>
<h2 id="section-7"></h2>
<p><a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> ECCV2018</p>
<p>数据集：Cityscapes NTHU(Rome, Rio, Tokyo,Taipei) GTA5 Cityscapes SYNTHIA Cityscapes</p>
<h2 id="section-8"></h2>
<p><a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a> ECCV2018</p>
<p>数据集： GTA5 Cityscapes SYNTHIA Cityscapes</p>
<h2 id="section-9"></h2>
<p><a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a> ECCV2018</p>
<p>数据集：GTAV，SYNTHIA，VIPER(proposed)，Cityscapes，CamVid</p>
<h1 id="指标比较">指标比较</h1>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>S. Hong, J. Oh, H. Lee, and B. Han. Learning transferrable knowledge for semantic segmentation with deep convolutional neural network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3204–3212, 2016.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>A. Kolesnikov and C. H. Lampert. Seed, expand and constrain: Three principles for weakly-supervised image segmentation. In European Conference on Computer Vision, pages 695–711. Springer, 2016.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>W. Shimoda and K. Yanai. Distinct class-specific saliency maps for weakly supervised semantic segmentation. In European Conference on Computer Vision, pages 218–234. Springer, 2016.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>J. Hoffman, D. Wang, F. Yu, and T. Darrell. Fcns in the wild: Pixel-level adversarial and constraint-based adaptation. arXiv preprint arXiv:1612.02649, 2016.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Y. Zhang, P. David, and B. Gong. Curriculum domain adaptation for semantic segmentation of urban scenes. In The IEEE International Conference on Computer Vision (ICCV), volume 2, page 6, 2017.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Y.-H. Chen, W.-Y. Chen, Y.-T. Chen, B.-C. Tsai, Y.-C. F. Wang, and M. Sun. No more discrimination: Cross city adaptation of road scene segmenters. arXiv preprint arXiv:1704.08509, 2017.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Y. Chen, W. Li, and L. Van Gool. Road: Reality oriented adaptation for semantic segmentation of urban scenes. arXiv preprint arXiv:1711.11556, 2017.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Sankaranarayanan S, Balaji Y, Jain A, et al. Learning From Synthetic Data: Addressing Domain Shift for Semantic Segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 3752-3761.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Tsai Y H, Hung W C, Schulter S, et al. Learning to adapt structured output space for semantic segmentation[J]. arXiv preprint arXiv:1802.10349, 2018. CVPR2018<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Hong W, Wang Z, Yang M, et al. Conditional Generative Adversarial Network for Structured Domain Adaptation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 1335-1344.<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Zou Y, Yu Z, Vijaya Kumar B V K, et al. Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 289-305.<a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Huang H, Huang Q, Kraehenbuehl P. Domain transfer through deep activation matching[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 590-605.<a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Saleh F S, Aliakbarian M S, Salzmann M, et al. Effective Use of Synthetic Data for Urban Scene Semantic Segmentation[J]. arXiv preprint arXiv:1807.06132, 2018.<a href="#fnref13">↩</a></p></li>
</ol>
</div>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/03/encoding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/03/encoding/" itemprop="url">
                  字符和编码
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-09-03 22:00:23" itemprop="dateCreated datePublished" datetime="2018-09-03T22:00:23+08:00">2018-09-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-09-04 14:58:57" itemprop="dateModified" datetime="2018-09-04T14:58:57+08:00">2018-09-04</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="文件编码">文件编码</h1>
<p>参考<a href="https://blog.csdn.net/gatieme/article/details/55045883" target="_blank" rel="external">这篇博客</a> 里面包含了linux下查看文件编码的方法</p>
<p>pycharm里也可以修改文本文件的编码， 位置在右下角 提供两个选项，reload convert</p>
<p>reload不改变文件时间的二进制值，只是修改读取方式，适用于出现了乱码需要寻找合适编码的情况</p>
<p>convert是使用不同的编码保存文件，会修改文件保存出来的二进制值，以及文件大小。</p>
<h1 id="字符和编码">字符和编码</h1>
<p><a href="http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html" target="_blank" rel="external">这篇博客</a>探讨不同概念的来源，没有涉及python2中的str和unicode，可以看下面的博客来理解</p>
<p>关于python2中的str和unicode看<a href="https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386819196283586a37629844456ca7e5a7faa9b94ee8000" target="_blank" rel="external">这篇博客</a></p>
<img src="/2018/09/03/encoding/encoding-1.JPG" title="encoding和py2的字符，unicode">
<img src="/2018/09/03/encoding/encoding-2.JPG" title="py2中str和unicode的转换">
<h1 id="py文件">py文件</h1>
<p>在py2的文件一开始，通常会写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br></pre></td></tr></table></figure>
<p>这句话的作用是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。 这句代码并不能保证.py文件自身的编码格式</p>
<p>需要设置.py文件自身的编码格式是UTF-8，而不是其他如GBK等，pycharm中如果开头添加了这句话，那么右下角的文件编码格式会自动锁定UTF-8，还是很贴心的。</p>
<h1 id="py2-和-py3的区别">py2 和 py3的区别</h1>
<p>fluent python的作者写的<a href="https://speakerdeck.com/ramalho/unicode-solutions-in-python-2-and-python-3?slide=22" target="_blank" rel="external">unicode solution</a></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/15/weak-pairwise-constraints/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/15/weak-pairwise-constraints/" itemprop="url">
                  Adapting Deep Visuomotor Representations with Weak Pairwise Constraints
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-15 16:22:04 / Modified: 16:25:18" itemprop="dateCreated datePublished" datetime="2018-08-15T16:22:04+08:00">2018-08-15</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="思路">思路</h1>
<p>针对的是虚拟数据到真实数据的无监督域适应的问题，并且希望利用虚拟数据和真实数据之间的成对关系，于是在训练中基于特征人为构造了成对数据，并且和网络训练迭代进行。</p>
<h1 id="实现">实现</h1>
<p>网络结构如下图所示： <img src="/2018/08/15/weak-pairwise-constraints/network.JPG" title="proposed network"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/15/simultanueous-deep-transfer-across-domain-and-task/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/15/simultanueous-deep-transfer-across-domain-and-task/" itemprop="url">
                  Simultaneous deep transfer across domains and tasks
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-15 13:29:54 / Modified: 16:09:47" itemprop="dateCreated datePublished" datetime="2018-08-15T13:29:54+08:00">2018-08-15</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="思路">思路</h1>
<p>本文针对的情况是目标域存在少量稀疏的带标签样本。通过domain confusion loss来获取领域一致的特征表示，同时由源域样本得到的soft label，建模类别之间的关系，指导目标域样本的分类，效果比hard label要好。</p>
<h1 id="方法">方法</h1>
<p>网络结构如下图所示： <img src="/2018/08/15/simultanueous-deep-transfer-across-domain-and-task/network.JPG" title="proposed network"></p>
<p>fcD层后面接的domain confusion loss和domain classifier loss是实现对抗学习的，目标和by backpropagation一样。</p>
<h2 id="aligning-domain-via-domain-confusion">Aligning domain via domain confusion</h2>
<p>首先要学习一个好的domain classifier，这样才能判别特征是不是真的有区分性，这个loss就是真实标签（图像属于哪个领域）和网络输出之间交叉熵损失。 <span class="math display">\[L_D(x_S,x_T,\theta_{repr}; \theta_D) = - \sum 1[y_D=d]logq_d\]</span></p>
<p>另外，为了最大程度的使domain classifier混淆，构造均匀分布和网络输出之间的交叉熵损失。 <span class="math display">\[L_D(x_S,x_T,\theta_D; \theta_{repr}) = - \sum\frac{1}{D} logq_d\]</span></p>
<p>这两部分的优化方向对于特征提取网络来说是冲突的，因此是迭代训练的。</p>
<h2 id="aligning-source-and-target-classes-via-soft-labels">Aligning source and target classes via soft labels</h2>
<p>对于都在目标域中存在的部分稀疏的标签，也将他们送到domain classifier中进行分类，但是使用hard label使得网络局限在提供的少量样本和少量类别中，因此受到网络蒸馏<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>的启发，一个大的网络可以“蒸馏”到一个小的网络中，通过将小网络的学习目标替换成大网络输出的soft label.这样可以使网络兼顾更多的类别。</p>
<p>简单来说，就是将source domain中每一类的所有样本的softmax输出的概率向量取平均，作为该类的soft label，用于target domain的交叉熵中需要拟合的分布。这样的soft label可以反映类别之间的相似关系。</p>
<p>在实际的实验中，一开始就在source domain上微调caffenet，然后生成soft label，后面就不动了（？）。</p>
<h1 id="代码">代码</h1>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>J. Ba and R. Caruana. Do deep nets really need to be deep? In Z. Ghahramani, M.Welling, C. Cortes, N. Lawrence, and K.Weinberger, editors, Advances in Neural Information Pro- cessing Systems 27, pages 2654–2662. Curran Associates, Inc., 2014.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network. In NIPS Deep Learning and Representa- tion Learning Workshop, 2014.<a href="#fnref2">↩</a></p></li>
</ol>
</div>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/15/adversarial-discriminative-domain-adaption/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/15/adversarial-discriminative-domain-adaption/" itemprop="url">
                  Adversarial Discriminative Domain Adaption
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-15 10:50:05 / Modified: 10:50:21" itemprop="dateCreated datePublished" datetime="2018-08-15T10:50:05+08:00">2018-08-15</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="abstract">Abstract</h1>
<p>之前的生成式方法展示了很好的视觉效果，但是在判别式任务上不是最优的，并且局限于较小的偏移；之前的判别式方法可以处理较大的偏移，引入了附加的权重，并且没有利用gan loss. 本文第一次为对抗式域适应提供了一个通用的框架，可以将最近的方法看做是该框架的一个特例。 # Generalized adverarial adaptation</p>
<h2 id="source-and-target-mappings-in">Source and target mappings In</h2>
<p>Coupled generative adversarial networks 在MNIST的无监督学习学习任务上取得了state-of-the-art 由于 ## Adversarial losses</p>
<h1 id="adversarial-discriminative-domain-adaptation">Adversarial discriminative domain adaptation</h1>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/13/unsupervised-image-to-image-translation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/13/unsupervised-image-to-image-translation/" itemprop="url">
                  Unsupervised Image-to-Image Translation Networks(UNIT)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-13 09:04:25 / Modified: 22:33:15" itemprop="dateCreated datePublished" datetime="2018-08-13T09:04:25+08:00">2018-08-13</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="思路">思路</h1>
<p>本文同样关注unsupvised设置，即只知道两个领域图像各自的边缘分布<span class="math inline">\(P_{x1}\)</span>和<span class="math inline">\(P_{x2}\)</span>，而不知道联合分布<span class="math inline">\(P_{x1,x2}\)</span>,和作者的上一篇Coupled GAN<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>一样. 上一篇论文的介绍看这里<a href="./coupled-gan.md">Coupled GAN</a>.</p>
<p>作者同样遵循了Coupled GAN中的假设：即对于不同领域的成对的图像<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>，存在一个共享的隐空间编码<span class="math inline">\(z\)</span>，既可以由图像计算编码<span class="math inline">\(z\)</span>，也可以从<span class="math inline">\(z\)</span>恢复两幅图像。Coupled GAN中两个生成器使用同一个随机变量作为输入，从而生成各自领域的图像。作者将生成器作为解码器，随机变量是隐空间的编码，在生成器前加入解码器。模型的结构如下： <img src="/2018/08/13/unsupervised-image-to-image-translation/UNIT-network-arch.JPG" title="network architecture of UNIT"></p>
<p>正因为有了同一个隐空间的表示，所以<span class="math inline">\(G_1(E_2(G_2(E_1(x_1))))\)</span>的输出就是<span class="math inline">\(x_1\)</span>，同理<span class="math inline">\(x_2\)</span>也可以实现cycle consistency，类似于<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>。但是由cycle consistency并不能推出这里的结构。</p>
<h1 id="代码">代码</h1>
<p>代码在<a href="https://github.com/mingyuliutw/unit" target="_blank" rel="external">这里</a></p>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>M.-Y. Liu and O. Tuzel. Coupled generative adversarial networks. Advances in Neural Information Processing Systems, 2016.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>T. Kim, M. Cha, H. Kim, J. Lee, and J. Kim. Learning to discover cross-domain relations with generative adversarial networks. International Conference on Machine Learning, 2017.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. International Conference on Computer Vision, 2017.<a href="#fnref3">↩</a></p></li>
</ol>
</div>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/12/coupled-gan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/12/coupled-gan/" itemprop="url">
                  Coupled GAN
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-12 16:26:18" itemprop="dateCreated datePublished" datetime="2018-08-12T16:26:18+08:00">2018-08-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-14 22:12:49" itemprop="dateModified" datetime="2018-08-14T22:12:49+08:00">2018-08-14</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="思路">思路</h1>
<p>提出可以学习多领域图像的联合分布的coupled GAN，不需要不同领域之间图像的对应关系。这是通过强制权重共享来限制网络容量，并且偏向于不同边缘分布的乘积来构造一个联合分布。</p>
<h1 id="方法">方法</h1>
<h2 id="网络结构">网络结构</h2>
<img src="/2018/08/12/coupled-gan/coupled-gan.JPG" title="network of coupled gan">
<p>采用了两个并列的GAN,各自的输入是不同领域的边缘分布采样的结果。GAN的生成器将<strong>同一个</strong>随机变量（高层语义信息）映射到不同的图像空间，并且通过权重共享的方式来约束不同领域的图像具有相同的高层信息，以及不同的底层实现方式。</p>
<p>生成器的输入只是随机变量，没有不同领域的图像（不同于conditional GAN），判别器比较的是各自领域的真实图像和生成图像。</p>
<p>结合下面的公式来理解： <img src="/2018/08/12/coupled-gan/coupled-gan-learning-formula.JPG" title="learning formula of coupled gan"></p>
<h2 id="生成器">生成器</h2>
<p>生成模型的前面几层用来解码高层的语义信息（输入的随机变量），而判别模型的后面几层用来提取高层语义信息（用于判断是否是真实图像）。</p>
<p>不同领域的对应图像共享比较抽象的语义信息，所以这里将生成器的前几层和判别器的后面几层的权重共享。</p>
<h2 id="判别器">判别器</h2>
<p>判别器的后面几层的权重也共享了，<strong>但是对学习联合分布是不重要的</strong>，可以帮助减少模型的参数量。</p>
<h2 id="重点">重点</h2>
<p>本文的主要贡献在于验证了只对<strong>边缘分布</strong><span class="math inline">\(P_{x1}\)</span>和<span class="math inline">\(P_{x2}\)</span>采样（每次两个领域的真实图像大概率是不对应的），学习到不同图像领域之间的配对关系（也就是<strong>联合分布</strong><span class="math inline">\(P_{x1,x2}\)</span>）。</p>
<p>本文的结构下也完成将一个领域的特定图像转换到另一个领域的任务。</p>
<p>自编码器学习<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>通过鼓励生成的<strong>图像对</strong>和目标的<strong>图像对</strong>之间的一致性来最小化loss（因此需要不同领域图像的对应关系），与之不同的是，本文采用的对抗学习仅仅是鼓励生成的<strong>图像对</strong>中的图像和各自领域的图像更像。（这么来看，还是很神奇的）。</p>
<p>解释是生成模型必须更加有效地利用模型参数来欺骗判别器，由于参数的共享，<strong>最有效的方式就是生成对应的图像</strong>。</p>
<p>CoGAN需要不同领域之间有共享的高层表示，如果没有的话，就会失败。（实验中有例子？）</p>
<h1 id="实验">实验</h1>
<p>评价指标：the pixel agreement ratio—the number of corresponding pixels that have the same value in the two images divided by the total image size. 在此之前还有没有类似的工作（不需要成对样本的监督），还是相当早的哈</p>
<p>MNIST上的任务： 1. 图像和边缘的对应 2. 图像和负的图像 3. 图像和90度旋转之后的图像</p>
<h2 id="wight-sharing">wight sharing</h2>
<p>生成模型的共享层越多，渲染的图像对就越像是从联合分布获取的真实样本。</p>
<h2 id="和条件gan的比较">和条件GAN的比较</h2>
<p>对比是这样的，条件GAN之前介绍过了，就是在普通GAN的生成器和判别器的输入中加入额外的信息。这里首先构建一个普通的GAN，其生成模型和判别模型和CoGAN中的一样。然后在生成模型和判别模型的输入中加入一个布尔值，用来指示图像来源于哪个领域。如果条件GAN也可以从边缘分布学习到联合分布的话，那么生成模型在同一个随机变量下，配合额外的布尔值，可以生成同一个数字（MNSIT上），但是风格不同。但实验表明，条件GAN并不能生成同样的数字。（可不可以加入其它限制，使得条件GAN也可以这样的任务？）</p>
<h2 id="人脸数据集">人脸数据集</h2>
<p>在CelebFaces Attributes dataset<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>上做了实验，这一数据集中每一张脸都有不同的属性，如金发，微笑，眼镜等。在训练的时候，将具有某项属性的图像作为Domain1，不具有这项属性的图像作为Domain2. 尽管这样的设置导致Domain1的图像数量少于Domain2，但是并没有影响训练。</p>
<p>实验结果显示同一个随机变量可以生成对应的具有某项属性和不具有这项属性的人脸图像，同时，随着随机变量的游走，两个领域的人脸变化会保持一致。</p>
<h2 id="应用">应用</h2>
<h3 id="无监督域适应">无监督域适应</h3>
<p>无监督域适应的问题是将一个在源域适用的分类器经过调整使之在目标域上也适用。</p>
<p>实验是从MNSIT到USPS，实验设置和<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>一样，从MNSIT中采样2000张图像，从USPS中，采样1800张图像，将USPS的分辨率缩放到和MNIST一样。</p>
<p>CoGAN用来生成图像，为了对<span class="math inline">\(D_1\)</span>的图像进行分类，在<span class="math inline">\(D_1\)</span>的判别器的最后一层里添加softmax层进行分类。CoGAN本身的训练和MNIST上的分类任务同时进行。注意到MNIST上的判别器和USPS上的判别器最后几层是共享的，USPS的判别器在分类USPS的数据时可以直接用。</p>
<p>在分类的时候，直接用真实图像作为判别器的输入，没有生成器的事，生成器只在训练的时候完成共享隐空间的设置。如果在判别器的后面几层不共享，不知道对于这个任务会不会有影响？如果只是单纯的用判别器部分来训练呢，可以完成UDA的任务吗？</p>
<p>对比的方法有<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a><a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a><a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a><a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<h3 id="跨域图像转换">跨域图像转换</h3>
<p>从概率分布的角度看，跨域图像转换的任务是给定Domain1中的一副图像<span class="math inline">\(x_1\)</span>，找到在Domain2中的对应的图像，也最大化联合概率分布<span class="math inline">\(P_{x1,x2}\)</span>.</p>
<p>当然啦，受制于模型本身的结构，不能直接完成图像的跨域转换，做法感觉是没有办法的办法。</p>
<p>首先是定义一个同领域图像相似度的损失函数，对于Domain1的图像<span class="math inline">\(x_1\)</span>，寻找最优的输入生成器<span class="math inline">\(G_1\)</span>随机变量<span class="math inline">\(z^*\)</span>，之后<span class="math inline">\(x_2=g_2(x^*)\)</span>就可以获得Domain2的对应图像 <span class="math display">\[z^* = argmin_z L(g_1(z),x_1)\]</span> 文章中的损失函数使用欧式距离，并用L-BFGS优化算法（还不了解）</p>
<p>实验结果发现，之后当输入图像可以被生成器<span class="math inline">\(g_1\)</span>生成时，转换效果才好，如果不能，则会生成模糊的图像。</p>
<h1 id="实现">实现</h1>
<p>代码在这里 https://github.com/mingyuliutw/cogan</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y Ng. Multimodal deep learning. In ICML, 2011.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Ziwei Liu, Ping Luo, XiaogangWang, and Xiaoou Tang. Deep learning face attributes in the wild. In ICCV, 2015.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Mingsheng Long, JianminWang, Guiguang Ding, Jiaguang Sun, and Philip Yu. Transfer feature learning with joint distribution adaptation. In ICCV, 2013.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Artem Rozantsev, Mathieu Salzmann, and Pascal Fua. Beyond sharing weights for deep domain adaptation. arXiv:1603.06432, 2016.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Basura Fernando, Tatiana Tommasi, and Tinne Tuytelaars. Joint cross-domain classification and subspace learning for unsupervised adaptation. Pattern Recognition Letters, 65:60–66, 2015.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv:1412.3474, 2014.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Mingsheng Long, JianminWang, Guiguang Ding, Jiaguang Sun, and Philip Yu. Transfer feature learning with joint distribution adaptation. In ICCV, 2013.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Artem Rozantsev, Mathieu Salzmann, and Pascal Fua. Beyond sharing weights for deep domain adaptation. arXiv:1603.06432, 2016.<a href="#fnref8">↩</a></p></li>
</ol>
</div>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/12/image-to-image-translation-conditional-gan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/12/image-to-image-translation-conditional-gan/" itemprop="url">
                  Image-to-Image Translation with Conditional Adversarial Networks
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-12 14:43:09" itemprop="dateCreated datePublished" datetime="2018-08-12T14:43:09+08:00">2018-08-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-15 10:31:43" itemprop="dateModified" datetime="2018-08-15T10:31:43+08:00">2018-08-15</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="思想">思想</h1>
<p>利用条件GAN来解决图像到图像的学习问题，不仅学习图像到图像的映射，同时学习一个损失函数来训练这一映射，使得这一方法可以应用于不同的任务，例如由标签生成图像，由边缘图像重建物体，为物体上色等。</p>
<p>生成器采用U-Net，判别器采用卷积“PatchGAN”分类器，仅在patch大小的区域对图像结构进行约束。</p>
<h1 id="方法">方法</h1>
<h2 id="网络结构">网络结构</h2>
<img src="/2018/08/12/image-to-image-translation-conditional-gan/pixel2pixel-network.JPG" title="network of pixel2piexl">
<p>随机噪声没有画出来</p>
<p>判别器判别的是{real_edge, real_photo} 和 {real_edge, fake_photo}的真假，这也是本文训练需要成对数据的原因。</p>
<h2 id="目标函数">目标函数</h2>
<p>使用条件GAN</p>
<p>在<strong>生成器</strong>网络上施加一个传统的loss函数，这里使用了L1 loss， L1会比L2更加清晰一些。目的是使生成器的输出和target domain的真实样本更加相似，可以看做是一个<strong>reconstruction loss</strong>。有了成对的数据，单纯使用Reconstruction loss也是可以训练得到结果的。实验中比较了只使用L1 loss的情况。</p>
<p>如果没有了噪声项，网络同样也可以学出来一个映射，但是这样会产生决定性的结果，从而不能够匹配除了delta函数之外的其他函数。但是作者初始的实验中，发现加入随机噪声并没有用，生成器还是会忽略随机噪声，这和<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>的观察一样。因此，在最终的模型中，在生成器的不同层添加了dropout（训练和测试时都用）。尽管如此，在输出的图像中，还是只观察到了很小的随机性。</p>
<h2 id="生成网络">生成网络</h2>
<p>image到image的转换是高分辨率的输入图像到高分辨率的输入图像的过程，图像之间的外观不同，但是图像的内在结构是一样的。 使用U-Net结构，带有skip连接，可以包含更多的底层信息。在图像着色的应用中，输入和输出共享了边缘的位置。</p>
<h2 id="markovian-discriminatorpatchgan">Markovian discriminator(PatchGAN)</h2>
<p>L1已经足够保证图像外观在低频的相似性了。</p>
<p>在高频，重点关注图像局部的结构。因此，针对高频的相似性，仅仅在图像patch级别做判断。</p>
<p>实验证明，patch的大小可以取得比全图小很多，同时图像具有很高的质量。</p>
<p>理论分析： 这样的判别器有效地将图像建模成一个马尔科夫随机场，假设不同patch内的像素是独立的。这一观点在PatchGAN<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>中进行了探索，也是其他领域如纹理生成，图像风格迁移<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>等的常识。</p>
<h2 id="优化和推断">优化和推断</h2>
<p>在测试的时候比较特殊，也使用了dropout。</p>
<p>BN层的参数使用的是测试batch的数据，而不是训练集上累计得到的数据。</p>
<p>当 batch size设为1的时候，就变成了实例归一化<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>，这在图像生成任务上证明是有效的，实验中采用的batchsize在1到10之间。</p>
<h1 id="实验">实验</h1>
<h2 id="评价指标">评价指标</h2>
<p><strong>FCN-score</strong>: 利用在数据集上训练好的FCN-8s模型，对由标签生成的图像进行语义分割的任务，看语义分割的指标，生成的图像越真实，语义分割的各项指标也应该越高。（如果是由图像生成标签，那么应该可以直接计算指标，原文给的Table5是labels到photo的双向箭头，不知道是不是两个任务都考虑了？）</p>
<h2 id="color">color</h2>
<p>L1 loss生成的图像，颜色分布最窄。加入cGAN可以拓宽颜色分布。</p>
<h2 id="pixelgan-patchgan-imagegan">PixelGAN PatchGAN ImageGAN</h2>
<p>改变判别器的patch大小，会有不同的效果。</p>
<p>1x1的patch对于是使图像锐化没有效果，但是可以增大颜色的分布。</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>M. Mathieu, C. Couprie, and Y. LeCun. Deep multi-scale video prediction beyond mean square error. ICLR, 2016. PatchGAN<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>C. Li and M. Wand. Precomputed real-time texture synthesis with markovian generative adversarial networks. ECCV, 2016.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Image style transfer using convolutional neural networks. CVPR 2016<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Combining markov random fields and convolutional neural networks for image synthesis. CVPR 2016<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>D. Ulyanov, A. Vedaldi, and V. Lempitsky. Instance normal- ization: The missing ingredient for fast stylization. arXiv preprint arXiv:1607.08022, 2016<a href="#fnref5">↩</a></p></li>
</ol>
</div>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/12/conditional-gan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/12/conditional-gan/" itemprop="url">
                  Conditional Generative Adversarial Nets
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-12 10:47:29 / Modified: 13:21:02" itemprop="dateCreated datePublished" datetime="2018-08-12T10:47:29+08:00">2018-08-12</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>原始的GAN可以通过在生成器和判别器上加入额外的依赖信息<span class="math inline">\(y\)</span>，构成条件GAN，<span class="math inline">\(y\)</span>可以是任意类型的附加信息，比如说标签信息，或者其他模态的信息。 原始的GAN的公式如下： <img src="/2018/08/12/conditional-gan/original-gan-formula.JPG" title="formula of original GAN"> 增加了额外输入信息的条件GAN公式如下： <img src="/2018/08/12/conditional-gan/conditional-gan-formula.JPG" title="formula of conditional GAN"> 网络结构如下： <img src="/2018/08/12/conditional-gan/conditional-gan.JPG" title="Architecture of Conditional GAN"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">10</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.4.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Muse</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  










  





  

  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    
  


  
  

  

  

  

  

  

</body>
</html>
